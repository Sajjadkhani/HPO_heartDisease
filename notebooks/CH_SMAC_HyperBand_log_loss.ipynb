{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/skhani/anaconda3/envs/SMAC2/lib/python3.10/site-packages/sklearn/datasets/_openml.py:322: UserWarning: Multiple active versions of the dataset matching the name heart-disease-dataset-(comprehensive) exist. Versions may be fundamentally different, returning version 1. Available versions:\n",
            "- version 1, status: active\n",
            "  url: https://www.openml.org/search?type=data&id=43672\n",
            "- version 2, status: active\n",
            "  url: https://www.openml.org/search?type=data&id=43682\n",
            "\n",
            "  warn(warning_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done Processing and downloading Heart-Disease-Dataset-(Comprehensive)\n"
          ]
        }
      ],
      "source": [
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "\n",
        "# From OpenML: https://www.openml.org/search?type=data&status=active&id=43672\n",
        "dataset_name = \"Heart-Disease-Dataset-(Comprehensive)\"\n",
        "\n",
        "\n",
        "def get_data_and_scoring_function(dataset_name):\n",
        "    X, y = sklearn.datasets.fetch_openml(dataset_name, as_frame=True, return_X_y=True)\n",
        "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
        "        X,\n",
        "        y,\n",
        "        random_state=0,\n",
        "        stratify=y,\n",
        "    )\n",
        "\n",
        "    def scoring_function(estimator):\n",
        "        predictions = estimator.predict_proba(X_test)[:, 1]\n",
        "        return sklearn.metrics.roc_auc_score(y_test, predictions)\n",
        "\n",
        "    def train_scoring_function(estimator):\n",
        "        predictions = estimator.predict_proba(X_train)[:, 1]\n",
        "        return sklearn.metrics.roc_auc_score(y_train, predictions)\n",
        "\n",
        "    def get_test_data():\n",
        "        return X_test, y_test\n",
        "\n",
        "    return (\n",
        "        X,\n",
        "        y,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        get_test_data,\n",
        "        scoring_function,\n",
        "        train_scoring_function,\n",
        "    )\n",
        "\n",
        "\n",
        "X, y, X_train, y_train, get_test_data, scoring_function, train_scoring_function = (\n",
        "    get_data_and_scoring_function(dataset_name)\n",
        ")\n",
        "\n",
        "X_test, y_test = get_test_data()\n",
        "\n",
        "print(f\"Done Processing and downloading {dataset_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# continuous and categorical features\n",
        "continuous_features = [\n",
        "    \"age\",\n",
        "    \"resting_bp_s\",\n",
        "    \"cholesterol\",\n",
        "    \"max_heart_rate\",\n",
        "    \"oldpeak\",\n",
        "]\n",
        "categorical_features = [\n",
        "    \"sex\",\n",
        "    \"chest_pain_type\",\n",
        "    \"fasting_blood_sugar\",\n",
        "    \"resting_ecg\",\n",
        "    \"exercise_angina\",\n",
        "    \"ST_slope\",\n",
        "]\n",
        "\n",
        "# Preprocessing for continuous features: Standardization\n",
        "# Preprocessing for categorical features: One-Hot Encoding\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), continuous_features),\n",
        "        (\"cat\", OneHotEncoder(), categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", RandomForestClassifier(random_state=42)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Splitting data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cost from negative log loss\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, KFold\n",
        "from sklearn.metrics import log_loss, make_scorer\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "from ConfigSpace import Categorical, Configuration, ConfigurationSpace, Float, Integer\n",
        "from ConfigSpace.conditions import EqualsCondition\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import log_loss, make_scorer\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate, KFold\n",
        "from sklearn.metrics import log_loss, make_scorer\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class RandomForestPipeline:\n",
        "\n",
        "    def __init__(self, seed: int = 0):\n",
        "        self.seed = seed\n",
        "\n",
        "    @property\n",
        "    def configspace(self) -> ConfigurationSpace:\n",
        "        \"\"\"\n",
        "        Configuration Space to optimizer over. In particular, optimize over\n",
        "        the hyperparameters of Random Forest.\n",
        "        \"\"\"\n",
        "        cs = ConfigurationSpace(seed=self.seed)\n",
        "\n",
        "        # Hyperparameters\n",
        "        n_estimators = Integer(\"n_estimators\", (10, 10000), default=100)\n",
        "        criterion = Categorical(\n",
        "            \"criterion\", [\"gini\", \"entropy\", \"log_loss\"], default=\"gini\"\n",
        "        )\n",
        "        max_depth = Integer(\"max_depth\", (1, 1000), default=None)\n",
        "        min_samples_split = Float(\"min_samples_split\", (0.0, 1))\n",
        "        min_samples_leaf = Integer(\"min_samples_leaf\", (1, 10), default=1)\n",
        "        min_weight_fraction_leaf = Float(\n",
        "            \"min_weight_fraction_leaf\", (0.0, 0.1), default=0.0\n",
        "        )\n",
        "        max_features = Float(\"max_features\", (0.0, 1))\n",
        "        max_leaf_nodes = Integer(\"max_leaf_nodes\", (10, 1000), default=None)\n",
        "        min_impurity_decrease = Float(\n",
        "            \"min_impurity_decrease\", (0.0, 0.02), default=0.0)\n",
        "        bootstrap = Categorical(\"bootstrap\", [True, False], default=True)\n",
        "        oob_score = Categorical(\"oob_score\", [True, False], default=False)\n",
        "        warm_start = Categorical(\"warm_start\", [True, False], default=False)\n",
        "        class_weight = Categorical(\n",
        "            \"class_weight\", [\"balanced\", \"balanced_subsample\"], default=None\n",
        "        )\n",
        "        ccp_alpha = Float(\"ccp_alpha\", (0.0, 0.001), default=0.0)\n",
        "        max_samples = Float(\"max_samples\", (0.0, 1.0), default=None)\n",
        "\n",
        "        cs.add_hyperparameters(\n",
        "            [\n",
        "                n_estimators,\n",
        "                criterion,\n",
        "                max_depth,\n",
        "                min_samples_split,\n",
        "                min_samples_leaf,\n",
        "                min_weight_fraction_leaf,\n",
        "                max_features,\n",
        "                max_leaf_nodes,\n",
        "                min_impurity_decrease,\n",
        "                bootstrap,\n",
        "                oob_score,\n",
        "                warm_start,\n",
        "                class_weight,\n",
        "                ccp_alpha,\n",
        "                max_samples,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Conditions\n",
        "        # OOB score only makes sense if bootstrap is True\n",
        "        oob_score_condition = EqualsCondition(\n",
        "            child=cs[\"oob_score\"], parent=cs[\"bootstrap\"], value=True\n",
        "        )\n",
        "        # \"balanced\" or \"balanced_subsample\" class weights is not recommended when warm_start=True\n",
        "        class_weight_condition = EqualsCondition(\n",
        "            child=cs[\"class_weight\"], parent=cs[\"warm_start\"], value=False\n",
        "        )\n",
        "        # max_features_condition = EqualsCondition(\n",
        "        #     child=cs[\"max_features\"], parent=cs[\"criterion\"], value=\"entropy\"\n",
        "        # )\n",
        "        # Creating the EqualsCondition to link `max_samples` activation with `bootstrap` being True\n",
        "        max_sample_condition = EqualsCondition(\n",
        "            child=cs[\"max_samples\"], parent=cs[\"bootstrap\"], value=True\n",
        "        )\n",
        "\n",
        "        cs.add_condition(oob_score_condition)\n",
        "        cs.add_condition(class_weight_condition)\n",
        "        cs.add_condition(max_sample_condition)\n",
        "\n",
        "        return cs\n",
        "\n",
        "    def train(self, config: Configuration, budget, seed: int = 0) -> float:\n",
        "        \"\"\"\n",
        "        Creates a RandomForestClassifier based on a configuration and evaluates it\n",
        "        on a dataset using cross-validation, with the evaluation metric being the negative log loss.\n",
        "        \"\"\"\n",
        "        # Here, budget refers to the fraction of the dataset to use\n",
        "        subset_size = int(budget * len(X_train))\n",
        "        X_train_subset = X_train[:subset_size]\n",
        "        y_train_subset = y_train[:subset_size]\n",
        "\n",
        "        config_dict = dict(config)\n",
        "\n",
        "        np.random.seed(seed=seed)\n",
        "\n",
        "        # Create a RandomForestClassifier with the specified hyperparameters\n",
        "        clf = RandomForestClassifier(\n",
        "            n_jobs=-1,\n",
        "            # max_samples=budget,\n",
        "            random_state=seed,\n",
        "            **config_dict\n",
        "        )\n",
        "\n",
        "        # Evaluate the classifier using cross-validation with negative log loss\n",
        "        scores = cross_val_score(\n",
        "            # clf, X_train, y_train, cv=5, scoring=\"neg_log_loss\")\n",
        "            clf,\n",
        "            X_train_subset,\n",
        "            y_train_subset,\n",
        "            cv=5,\n",
        "            scoring=\"neg_log_loss\",\n",
        "        )\n",
        "\n",
        "        # Return the mean of the negative log loss scores\n",
        "        return -np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-lmm7ipcnzM",
        "outputId": "cc712d3b-a7a0-4e84-ff09-e34840044a70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Configuration(values={\n",
            "  'bootstrap': False,\n",
            "  'ccp_alpha': 0.0007917250380826646,\n",
            "  'criterion': 'log_loss',\n",
            "  'max_depth': 265,\n",
            "  'max_features': 0.359507900573786,\n",
            "  'max_leaf_nodes': 575,\n",
            "  'min_impurity_decrease': 0.0031793916729103942,\n",
            "  'min_samples_leaf': 10,\n",
            "  'min_samples_split': 0.317983179393976,\n",
            "  'min_weight_fraction_leaf': 0.03185689524513237,\n",
            "  'n_estimators': 6782,\n",
            "  'warm_start': True,\n",
            "}), Configuration(values={\n",
            "  'bootstrap': False,\n",
            "  'ccp_alpha': 0.0005288949197529045,\n",
            "  'class_weight': 'balanced_subsample',\n",
            "  'criterion': 'log_loss',\n",
            "  'max_depth': 775,\n",
            "  'max_features': 0.43703195379934145,\n",
            "  'max_leaf_nodes': 444,\n",
            "  'min_impurity_decrease': 0.0022075028232861026,\n",
            "  'min_samples_leaf': 5,\n",
            "  'min_samples_split': 0.41426299451466997,\n",
            "  'min_weight_fraction_leaf': 0.06674103799636817,\n",
            "  'n_estimators': 2707,\n",
            "  'warm_start': False,\n",
            "}), Configuration(values={\n",
            "  'bootstrap': False,\n",
            "  'ccp_alpha': 0.0005680445610939324,\n",
            "  'class_weight': 'balanced_subsample',\n",
            "  'criterion': 'entropy',\n",
            "  'max_depth': 457,\n",
            "  'max_features': 0.6976311959272649,\n",
            "  'max_leaf_nodes': 989,\n",
            "  'min_impurity_decrease': 0.013126591789305468,\n",
            "  'min_samples_leaf': 10,\n",
            "  'min_samples_split': 0.06414749634878436,\n",
            "  'min_weight_fraction_leaf': 0.013179786240439218,\n",
            "  'n_estimators': 7355,\n",
            "  'warm_start': False,\n",
            "}), Configuration(values={\n",
            "  'bootstrap': False,\n",
            "  'ccp_alpha': 0.000925596638292661,\n",
            "  'criterion': 'log_loss',\n",
            "  'max_depth': 569,\n",
            "  'max_features': 0.06022547162926983,\n",
            "  'max_leaf_nodes': 111,\n",
            "  'min_impurity_decrease': 0.0027636590269722763,\n",
            "  'min_samples_leaf': 7,\n",
            "  'min_samples_split': 0.6924721193700198,\n",
            "  'min_weight_fraction_leaf': 0.07163272041185656,\n",
            "  'n_estimators': 9623,\n",
            "  'warm_start': True,\n",
            "}), Configuration(values={\n",
            "  'bootstrap': True,\n",
            "  'ccp_alpha': 7.103605819788694e-05,\n",
            "  'class_weight': 'balanced',\n",
            "  'criterion': 'gini',\n",
            "  'max_depth': 19,\n",
            "  'max_features': 0.6667667154456677,\n",
            "  'max_leaf_nodes': 216,\n",
            "  'max_samples': 0.5699649107012649,\n",
            "  'min_impurity_decrease': 0.00393164723360107,\n",
            "  'min_samples_leaf': 8,\n",
            "  'min_samples_split': 0.5666014542065752,\n",
            "  'min_weight_fraction_leaf': 0.028940609294720112,\n",
            "  'n_estimators': 2495,\n",
            "  'oob_score': False,\n",
            "  'warm_start': False,\n",
            "}), Configuration(values={\n",
            "  'bootstrap': False,\n",
            "  'ccp_alpha': 8.712929970154071e-05,\n",
            "  'criterion': 'entropy',\n",
            "  'max_depth': 618,\n",
            "  'max_features': 0.6706378696181594,\n",
            "  'max_leaf_nodes': 169,\n",
            "  'min_impurity_decrease': 0.007374503413219283,\n",
            "  'min_samples_leaf': 1,\n",
            "  'min_samples_split': 0.2653894909394454,\n",
            "  'min_weight_fraction_leaf': 0.018319136200711683,\n",
            "  'n_estimators': 5766,\n",
            "  'warm_start': True,\n",
            "}), Configuration(values={\n",
            "  'bootstrap': True,\n",
            "  'ccp_alpha': 2.021839744032572e-05,\n",
            "  'class_weight': 'balanced',\n",
            "  'criterion': 'gini',\n",
            "  'max_depth': 613,\n",
            "  'max_features': 0.2103825610738409,\n",
            "  'max_leaf_nodes': 657,\n",
            "  'max_samples': 0.5743252488495788,\n",
            "  'min_impurity_decrease': 0.016419864596958704,\n",
            "  'min_samples_leaf': 3,\n",
            "  'min_samples_split': 0.5232480534666997,\n",
            "  'min_weight_fraction_leaf': 0.05865129348100832,\n",
            "  'n_estimators': 5925,\n",
            "  'oob_score': True,\n",
            "  'warm_start': False,\n",
            "}), Configuration(values={\n",
            "  'bootstrap': False,\n",
            "  'ccp_alpha': 0.000832619845547938,\n",
            "  'class_weight': 'balanced',\n",
            "  'criterion': 'log_loss',\n",
            "  'max_depth': 617,\n",
            "  'max_features': 0.1289262976548533,\n",
            "  'max_leaf_nodes': 261,\n",
            "  'min_impurity_decrease': 0.0019420255158612255,\n",
            "  'min_samples_leaf': 2,\n",
            "  'min_samples_split': 0.09394051075844168,\n",
            "  'min_weight_fraction_leaf': 0.002010754618749355,\n",
            "  'n_estimators': 5727,\n",
            "  'warm_start': False,\n",
            "}), Configuration(values={\n",
            "  'bootstrap': False,\n",
            "  'ccp_alpha': 0.0007781567509498505,\n",
            "  'class_weight': 'balanced_subsample',\n",
            "  'criterion': 'entropy',\n",
            "  'max_depth': 944,\n",
            "  'max_features': 0.31542835092418386,\n",
            "  'max_leaf_nodes': 472,\n",
            "  'min_impurity_decrease': 0.016758898149976078,\n",
            "  'min_samples_leaf': 3,\n",
            "  'min_samples_split': 0.5759464955561793,\n",
            "  'min_weight_fraction_leaf': 0.08289400292173632,\n",
            "  'n_estimators': 2238,\n",
            "  'warm_start': False,\n",
            "}), Configuration(values={\n",
            "  'bootstrap': True,\n",
            "  'ccp_alpha': 0.0008700121482468192,\n",
            "  'class_weight': 'balanced',\n",
            "  'criterion': 'entropy',\n",
            "  'max_depth': 682,\n",
            "  'max_features': 0.3637107709426226,\n",
            "  'max_leaf_nodes': 252,\n",
            "  'max_samples': 0.43141843543397396,\n",
            "  'min_impurity_decrease': 0.0019219681578792613,\n",
            "  'min_samples_leaf': 2,\n",
            "  'min_samples_split': 0.9292961975762141,\n",
            "  'min_weight_fraction_leaf': 0.0004695476192547066,\n",
            "  'n_estimators': 9528,\n",
            "  'oob_score': False,\n",
            "  'warm_start': False,\n",
            "})]\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestPipeline()\n",
        "cs = rf.configspace\n",
        "config = cs.sample_configuration(10)\n",
        "\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from smac import HyperbandFacade, Scenario\n",
        "\n",
        "rf = RandomForestPipeline()\n",
        "\n",
        "seeds = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
        "\n",
        "for seed in seeds:\n",
        "    scenario = Scenario(\n",
        "        rf.configspace,\n",
        "        name=\"RandomForest_HB_neg_log_loss\",\n",
        "        n_trials=1000,\n",
        "        objectives=[\"neg_log_loss\"],\n",
        "        deterministic=True,\n",
        "        walltime_limit=60 * 60,\n",
        "        seed=seed,\n",
        "        n_workers=15,\n",
        "        min_budget=0.1,  # Use 10% of the data as the minimum budget\n",
        "        max_budget=1.0,  # Use 100% of the data as the maximum budget\n",
        "    )\n",
        "\n",
        "    smac = HyperbandFacade(\n",
        "        scenario=scenario,\n",
        "        target_function=rf.train,  # The function to optimize\n",
        "        overwrite=True,\n",
        "    )\n",
        "    incumbent = smac.optimize()\n",
        "    print(f\"Seed: {seed}, Incumbent: {incumbent}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def test_score_rf(incumbent, seed):\n",
        "    \"\"\"\n",
        "    Evaluates the test accuracy of the Random Forest model configured with the given hyperparameters\n",
        "    and provides a classification report.\n",
        "\n",
        "    :param incumbent: dict, the configuration of hyperparameters for the RandomForestClassifier\n",
        "    :param budget: int, not used in this simplified version but could be used for controlling model complexity or training time\n",
        "    :param seed: int, the seed for random operations to ensure reproducibility\n",
        "\n",
        "    :return: tuple, containing the accuracy of the model on the test set and the classification report\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a RandomForestClassifier with the incumbent configuration\n",
        "    clf = RandomForestClassifier(**incumbent, random_state=seed)\n",
        "\n",
        "    # Train the model\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    predictions = clf.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    # Generate classification report\n",
        "    class_report = classification_report(y_test, predictions)\n",
        "\n",
        "    # Return accuracy and classification report\n",
        "    return accuracy, class_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.\n",
            "Incumbent cost: 0.3528526231196531\n",
            "Incumbent accuracy: 0.6471473768803468\n",
            "Incumbent test accuracy: 0.9033613445378151\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.84      0.89       107\n",
            "         1.0       0.88      0.95      0.92       131\n",
            "\n",
            "    accuracy                           0.90       238\n",
            "   macro avg       0.91      0.90      0.90       238\n",
            "weighted avg       0.91      0.90      0.90       238\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Validate the incumbent configuration with a different seed\n",
        "incumbent_cost = smac.validate(incumbent, seed=1235)\n",
        "print(f\"Incumbent cost: {incumbent_cost}\")\n",
        "print(f\"Incumbent accuracy: {1 - incumbent_cost}\")\n",
        "\n",
        "# Evaluate test score and classification report\n",
        "test_score, classification_report = test_score_rf(incumbent, seed=1235)\n",
        "print(f\"Incumbent test accuracy: {test_score}\")\n",
        "print(\"Classification Report:\\n\", classification_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjj5hwfvfpD_",
        "outputId": "b9dd7c6b-b00f-4920-ce6a-f6464966991c"
      },
      "outputs": [],
      "source": [
        "incumbent_cost = smac.validate(incumbent, seed=1235)\n",
        "print(f\"Incumbent cost: {incumbent_cost}\")\n",
        "print(f\"Incumbent accuracy {1-incumbent_cost}\")\n",
        "\n",
        "test_score = testscore_rf(incumbent, budget=1, seed=1235)\n",
        "print(f\"Incumbent test accuracy {test_score}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
